{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: /orfeo/cephfs/home/dssc/francescortu/easyroutine\n"
     ]
    }
   ],
   "source": [
    "from easyroutine import path_to_parents\n",
    "path_to_parents(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[03/14/25 12:03:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Info logging enabled for easyroutine.  \u001b]8;id=513513;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/logger.py\u001b\\\u001b[2mlogger.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=484543;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/logger.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "# You can set the logging level for the entire library using the following utility function\n",
    "from easyroutine.logger import enable_debug_logging,enable_info_logging,enable_warning_logging, setup_logging\n",
    "\n",
    "enable_info_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooked Model\n",
    "The central element of the interpretability sub-module is the `HookedModel` class, that is a wrapper around a HuggingFace model with hooks to extract intermediate representations. For now we support just few models, but we are working to extend the list.  Check the documentation for the full list of supported models.\n",
    "For this tutorial we will use the tiny 2 layers transformer model `hf-internal-testing/tiny-random-LlamaForCausalLM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/dssc/francescortu/easyroutine/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[03/14/25 12:01:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found a wrapper for LlamaAttention    \u001b]8;id=751706;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/module_wrappers/manager.py\u001b\\\u001b[2mmanager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=110166;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/module_wrappers/manager.py#57\u001b\\\u001b[2m57\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HookedModel: Model loaded in \u001b[1;36m1\u001b[0m  \u001b]8;id=47130;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=35492;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#187\u001b\\\u001b[2m187\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         devices. First device: cu\u001b[1;92mda:0\u001b[0m   \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m  HookedModel:                   \u001b]8;id=546509;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=850483;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#203\u001b\\\u001b[2m203\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m                                     The \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         model is using the custom eager \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         attention implementation that   \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         support attention matrix hooks  \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         because I get                   \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         config.attn_impelemntation ==   \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[32m'custom_eager'\u001b[0m. If you don't    \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         want this, you can call         \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         HookedModel.restore_original_mo \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         dules.                          \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m                                     How \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         ever, we reccomend using this   \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         implementation since the base   \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         one do not contains attention   \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         matrix hook resulting in        \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         unexpected behaviours.          \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m                                         \u001b[2m                   \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HookedModel: Setting custom     \u001b]8;id=729862;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=31359;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#263\u001b\\\u001b[2m263\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         modules.                        \u001b[2m                   \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from easyroutine.interpretability import HookedModel\n",
    "\n",
    "# takes the usual args of the HF library\n",
    "model = HookedModel.from_pretrained(\"hf-internal-testing/tiny-random-LlamaForCausalLM\", device_map=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedModel(model_name=hf-internal-testing/tiny-random-LlamaForCausalLM):\n",
      "        LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 16, padding_idx=31999)\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttentionWrapper(\n",
      "          (q_proj): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (k_proj): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (v_proj): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (o_proj): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (attention_matrix_hook): AttentionMatrixHookModule()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=16, out_features=64, bias=False)\n",
      "          (up_proj): Linear(in_features=16, out_features=64, bias=False)\n",
      "          (down_proj): Linear(in_features=64, out_features=16, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((16,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((16,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((16,), eps=1e-06)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=16, out_features=32000, bias=False)\n",
      ")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `HookedModel` class automatically load also the tokenizer. To get the tokenizer we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model.get_tokenizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Multimodal Models__\n",
    "For multimodal model we have also the `HookedModel.get_processor()` method that return the processor for the multimodal model and the `HookedModel.get_text_tokenizer()` method that return the tokenizer for the text part of the multimodal model. In addition, it is possible to set the modality to use with the `HookedModel.use_language_model()` and `HookedModel.use_full_model()` methods. This methods are useful to switch between the language backbone and the full model with the visual encoder. It is useful in model like LlaVA which expect always the visual input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to do a forward pass with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,   450,  4996, 17354,  1701, 29916,   432, 17204,   975,   278,\n",
      "         17366, 11203]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "ActivationCache(logits: tensor([[[-0.0430, -0.0654, -0.1011,  ..., -0.1387,  0.0483,  0.0708],\n",
      "         [ 0.0603, -0.0422,  0.0654,  ...,  0.0310,  0.0212, -0.0014],\n",
      "         [-0.0267,  0.0522, -0.0840,  ...,  0.1367,  0.0447, -0.1011],\n",
      "         ...,\n",
      "         [-0.0339, -0.0522, -0.0684,  ..., -0.0957,  0.0447,  0.0189],\n",
      "         [-0.0270,  0.0024,  0.0011,  ...,  0.0369,  0.0029, -0.0118],\n",
      "         [-0.0222,  0.0815,  0.0247,  ...,  0.0791,  0.0762, -0.1357]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16), mapping_index: {'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]})\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "\n",
    "output = model(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eso': 4.315376281738281e-05, 'además': 4.267692565917969e-05, 'bright': 4.1961669921875e-05, 'ionic': 4.1961669921875e-05, 'presidente': 4.172325134277344e-05, 'iar': 4.172325134277344e-05, '/`': 4.1484832763671875e-05, 'película': 4.1484832763671875e-05, 'Brown': 4.1484832763671875e-05, 'nested': 4.1484832763671875e-05}\n"
     ]
    }
   ],
   "source": [
    "# Model have also a .predict method\n",
    "output = model.predict(inputs=inputs,k=10)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the return object of the forward pass is an ActivationCache object, i.e. a dictonary that could contains the hidden states of the model. Now let's see how we can extract the hidden states of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyroutine.interpretability import ExtractionConfig\n",
    "\n",
    "extraction_config = ExtractionConfig(\n",
    "    extract_resid_out=True, # extract, per layer the outptu of each layer\n",
    "    extract_attn_in=True, # extract, per layer the input of each \n",
    ")\n",
    "\n",
    "output = model(\n",
    "    inputs,\n",
    "    extraction_config=extraction_config, # extract the requested activations\n",
    "    target_token_positions=[\"last\", -3] # extract at the last token and the third to last token position (support also \"all\", \"all-text\", \"all-image\", and  other more complex configurations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the extracted hidden states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations extracted: dict_keys(['attn_in_0', 'resid_out_0', 'attn_in_1', 'resid_out_1', 'logits', 'mapping_index'])\n",
      "Resid shape (batch,target_token_positions,hiddend_dim): torch.Size([1, 2, 16])\n",
      "{'last': [0], -3: [1]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Activations extracted:\", output.keys())\n",
    "print(\"Resid shape (n_elements,target_token_positions,hiddend_dim):\", output[\"resid_out_1\"].shape)\n",
    "\n",
    "# so output[\"resid_out_1\"][0,0] is the residual of the first layer of the last token and output[\"resid_out_1\"][0,1] is the residual of the first layer of the third to last token. If you are unsure of the mapping you can use\n",
    "\n",
    "print(output[\"mapping_index\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to extract the hidden states of a full dataset, you can use the `extract_cache` methods, given a dataloader that should have, for each element, the keys that the model expect (for sure `input_ids` and `attention_mask`, but maybe also `pixel_values` and `image_sizes` for multimodal models). The `extract_cache` method will return a list of ActivationCache objects, one for each element of the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': tensor([[    1,   450,  4996, 17354,  1701, 29916,   432, 17204,   975,   278,\n",
      "         17366, 11203]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[   1,  450, 6635,  338,  373,  278, 1591]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}]\n"
     ]
    }
   ],
   "source": [
    "dataloader = [\n",
    "    tokenizer(\"The quick brown fox jumps over the lazy dog\", return_tensors=\"pt\"),\n",
    "    tokenizer(\"The cat is on the table\", return_tensors=\"pt\"),\n",
    "]\n",
    "print(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[03/14/25 12:27:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HookedModel: Extracting cache  \u001b]8;id=940081;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=416787;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#1138\u001b\\\u001b[2m1138\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m[03/14/25 12:27:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HookedModel: Forward pass      \u001b]8;id=216125;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=507788;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#1142\u001b\\\u001b[2m1142\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         started                        \u001b[2m                    \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting cache:: 100%|██████████| 2/2 [00:00<00:00, 33.50it/s]\n"
     ]
    }
   ],
   "source": [
    "cache = model.extract_cache(\n",
    "    dataloader=dataloader,\n",
    "    extraction_config=extraction_config,\n",
    "    target_token_positions=[\"last\", -3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 16])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[\"resid_out_1\"].shape # (2,2,16) 2 samples, 2 target_token_positions, 16 hidden dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__WARNING__: Obviously, if you want to extract `all` positions, since all the tensors will have different shapes, the `extract_cache` method will return a list of tensors, one for each element in the dataloader. However, you can compute the mean of the hidden states of all the positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[03/14/25 12:30:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HookedModel: Extracting cache  \u001b]8;id=247977;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=602632;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#1138\u001b\\\u001b[2m1138\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HookedModel: Forward pass      \u001b]8;id=305166;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=891987;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#1142\u001b\\\u001b[2m1142\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         started                        \u001b[2m                    \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting cache::   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.cat failed for tensor \u001b]8;id=238499;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=111846;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         shapes \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m,   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m and \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m,  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m: Sizes of tensors must \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         match except in dimension   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m. Expected size \u001b[1;36m12\u001b[0m but got \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         size \u001b[1;36m7\u001b[0m for tensor number \u001b[1;36m1\u001b[0m  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         in the list.; trying        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         torch.stack.                \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.stack also failed:    \u001b]8;id=966845;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=377170;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         stack expects each tensor   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         to be equal size, but got   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m0\u001b[0m and  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m1\u001b[0m;      \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         switching to list           \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         aggregation.                \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.cat failed for tensor \u001b]8;id=235764;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=364775;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         shapes \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m,   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m and \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m,  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m: Sizes of tensors must \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         match except in dimension   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m. Expected size \u001b[1;36m12\u001b[0m but got \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         size \u001b[1;36m7\u001b[0m for tensor number \u001b[1;36m1\u001b[0m  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         in the list.; trying        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         torch.stack.                \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.stack also failed:    \u001b]8;id=978729;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=649774;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         stack expects each tensor   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         to be equal size, but got   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m0\u001b[0m and  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m1\u001b[0m;      \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         switching to list           \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         aggregation.                \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.cat failed for tensor \u001b]8;id=792959;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=173811;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         shapes \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m,   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m and \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m,  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m: Sizes of tensors must \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         match except in dimension   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m. Expected size \u001b[1;36m12\u001b[0m but got \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         size \u001b[1;36m7\u001b[0m for tensor number \u001b[1;36m1\u001b[0m  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         in the list.; trying        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         torch.stack.                \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.stack also failed:    \u001b]8;id=817816;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=146349;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         stack expects each tensor   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         to be equal size, but got   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m0\u001b[0m and  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m1\u001b[0m;      \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         switching to list           \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         aggregation.                \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.cat failed for tensor \u001b]8;id=363382;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=878181;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         shapes \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m,   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m and \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m,  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m: Sizes of tensors must \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         match except in dimension   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m. Expected size \u001b[1;36m12\u001b[0m but got \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         size \u001b[1;36m7\u001b[0m for tensor number \u001b[1;36m1\u001b[0m  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         in the list.; trying        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         torch.stack.                \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.stack also failed:    \u001b]8;id=747415;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=856514;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         stack expects each tensor   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         to be equal size, but got   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m0\u001b[0m and  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m1\u001b[0m;      \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         switching to list           \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         aggregation.                \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.cat failed for tensor \u001b]8;id=602925;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=359856;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         shapes \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m,   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m32000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m and \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m,  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m7\u001b[0m, \u001b[1;36m32000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m: Sizes of        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         tensors must match except   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         in dimension \u001b[1;36m0\u001b[0m. Expected    \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         size \u001b[1;36m12\u001b[0m but got size \u001b[1;36m7\u001b[0m for  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         tensor number \u001b[1;36m1\u001b[0m in the      \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         list.; trying torch.stack.  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.stack also failed:    \u001b]8;id=725341;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=586094;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         stack expects each tensor   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         to be equal size, but got   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m32000\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m0\u001b[0m   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         and \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m32000\u001b[0m\u001b[1m]\u001b[0m at entry  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m1\u001b[0m; switching to list        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         aggregation.                \u001b[2m                       \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting cache:: 100%|██████████| 2/2 [00:00<00:00, 76.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[-0.0181, -0.0427,  0.0099,  0.0004,  0.0059, -0.0098, -0.0219,\n",
      "          -0.0154,  0.0082, -0.0272, -0.0104, -0.0026, -0.0126,  0.0266,\n",
      "           0.0142, -0.0203],\n",
      "         [-0.0019,  0.0297,  0.0276,  0.0126, -0.0024, -0.0034, -0.0217,\n",
      "           0.0151,  0.0077,  0.0161,  0.0309,  0.0063, -0.0049, -0.0225,\n",
      "           0.0442,  0.0018],\n",
      "         [-0.0129,  0.0014,  0.0141,  0.0187,  0.0045,  0.0045,  0.0051,\n",
      "           0.0181, -0.0087,  0.0282,  0.0266,  0.0012,  0.0215, -0.0006,\n",
      "           0.0127, -0.0133],\n",
      "         [-0.0208, -0.0115, -0.0349, -0.0236,  0.0184, -0.0576, -0.0167,\n",
      "          -0.0193,  0.0247,  0.0197,  0.0054, -0.0256, -0.0046, -0.0093,\n",
      "           0.0077,  0.0096],\n",
      "         [-0.0217, -0.0076, -0.0269, -0.0206,  0.0026, -0.0339,  0.0050,\n",
      "          -0.0022,  0.0112,  0.0009,  0.0117,  0.0052,  0.0206,  0.0280,\n",
      "          -0.0186,  0.0134],\n",
      "         [-0.0078, -0.0295, -0.0012, -0.0271, -0.0292,  0.0150, -0.0095,\n",
      "           0.0256, -0.0189,  0.0284, -0.0018, -0.0025, -0.0092,  0.0114,\n",
      "           0.0500,  0.0059],\n",
      "         [-0.0026,  0.0253,  0.0075,  0.0145, -0.0283,  0.0089,  0.0024,\n",
      "           0.0083, -0.0162, -0.0147, -0.0129, -0.0254,  0.0049,  0.0104,\n",
      "          -0.0219, -0.0060],\n",
      "         [-0.0247, -0.0122, -0.0136, -0.0114, -0.0007, -0.0483,  0.0481,\n",
      "           0.0250,  0.0162,  0.0096,  0.0043,  0.0012,  0.0071, -0.0034,\n",
      "           0.0048, -0.0008],\n",
      "         [-0.0048, -0.0498,  0.0016, -0.0052, -0.0203,  0.0036, -0.0042,\n",
      "           0.0128, -0.0254, -0.0339,  0.0170, -0.0006,  0.0187, -0.0503,\n",
      "           0.0155,  0.0193],\n",
      "         [-0.0069, -0.0337, -0.0125,  0.0320,  0.0028,  0.0091, -0.0166,\n",
      "          -0.0474,  0.0139,  0.0283, -0.0060,  0.0131, -0.0085,  0.0276,\n",
      "           0.0432, -0.0400],\n",
      "         [ 0.0164,  0.0063, -0.0126,  0.0466, -0.0026, -0.0217,  0.0049,\n",
      "          -0.0098,  0.0347,  0.0233,  0.0054, -0.0405,  0.0199,  0.0017,\n",
      "           0.0273,  0.0095],\n",
      "         [-0.0076,  0.0159,  0.0352,  0.0047, -0.0025,  0.0221, -0.0210,\n",
      "           0.0015, -0.0162,  0.0253,  0.0112,  0.0129, -0.0214, -0.0090,\n",
      "          -0.0525, -0.0330]]], dtype=torch.bfloat16), tensor([[[-0.0181, -0.0427,  0.0099,  0.0004,  0.0059, -0.0098, -0.0219,\n",
      "          -0.0154,  0.0082, -0.0272, -0.0104, -0.0026, -0.0126,  0.0266,\n",
      "           0.0142, -0.0203],\n",
      "         [-0.0019,  0.0297,  0.0276,  0.0126, -0.0024, -0.0034, -0.0217,\n",
      "           0.0151,  0.0077,  0.0161,  0.0309,  0.0063, -0.0049, -0.0225,\n",
      "           0.0442,  0.0018],\n",
      "         [-0.0237, -0.0135,  0.0222,  0.0317,  0.0098, -0.0564,  0.0038,\n",
      "          -0.0273, -0.0104, -0.0226,  0.0236,  0.0170,  0.0092, -0.0072,\n",
      "           0.0240, -0.0437],\n",
      "         [ 0.0031, -0.0154, -0.0035,  0.0322, -0.0064,  0.0139,  0.0003,\n",
      "           0.0003, -0.0317,  0.0040, -0.0277,  0.0243, -0.0186, -0.0276,\n",
      "           0.0021, -0.0058],\n",
      "         [-0.0166,  0.0108,  0.0076,  0.0187,  0.0182,  0.0107,  0.0061,\n",
      "           0.0002, -0.0145, -0.0132,  0.0306,  0.0165,  0.0080,  0.0075,\n",
      "           0.0223,  0.0143],\n",
      "         [-0.0096, -0.0413, -0.0120,  0.0393,  0.0008,  0.0066, -0.0261,\n",
      "          -0.0503,  0.0126,  0.0277, -0.0010,  0.0107, -0.0023,  0.0227,\n",
      "           0.0325, -0.0391],\n",
      "         [-0.0159, -0.0085,  0.0020, -0.0128, -0.0012,  0.0063, -0.0248,\n",
      "           0.0048,  0.0327,  0.0447,  0.0245,  0.0354,  0.0055, -0.0028,\n",
      "           0.0317, -0.0002]]], dtype=torch.bfloat16)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cache = model.extract_cache(\n",
    "    dataloader=dataloader,\n",
    "    extraction_config=extraction_config,\n",
    "    target_token_positions=[\"all\"]\n",
    ")\n",
    "print(cache[\"resid_out_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[03/14/25 12:32:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HookedModel: Extracting cache  \u001b]8;id=1210;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=664325;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#1138\u001b\\\u001b[2m1138\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HookedModel: Forward pass      \u001b]8;id=56015;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py\u001b\\\u001b[2mhooked_model.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=655390;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/hooked_model.py#1142\u001b\\\u001b[2m1142\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         started                        \u001b[2m                    \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting cache::   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.cat failed for tensor \u001b]8;id=2255;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=682719;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         shapes \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m,   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m32000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m and \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m,  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m7\u001b[0m, \u001b[1;36m32000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m: Sizes of        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         tensors must match except   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         in dimension \u001b[1;36m0\u001b[0m. Expected    \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         size \u001b[1;36m12\u001b[0m but got size \u001b[1;36m7\u001b[0m for  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         tensor number \u001b[1;36m1\u001b[0m in the      \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         list.; trying torch.stack.  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m torch.stack also failed:    \u001b]8;id=738253;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py\u001b\\\u001b[2mactivation_cache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=970844;file:///orfeo/cephfs/home/dssc/francescortu/easyroutine/easyroutine/interpretability/activation_cache.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         stack expects each tensor   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         to be equal size, but got   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m32000\u001b[0m\u001b[1m]\u001b[0m at entry \u001b[1;36m0\u001b[0m   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         and \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m32000\u001b[0m\u001b[1m]\u001b[0m at entry  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m1\u001b[0m; switching to list        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         aggregation.                \u001b[2m                       \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting cache:: 100%|██████████| 2/2 [00:00<00:00, 129.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cache = model.extract_cache(  # we will get an warning for the logits\n",
    "    dataloader=dataloader, \n",
    "    extraction_config=ExtractionConfig(\n",
    "    extract_resid_out=True, # extract, per layer the outptu of each layer\n",
    "    extract_attn_in=True, # extract, per layer the input of each \n",
    "    avg=True,\n",
    "),\n",
    "    target_token_positions=[\"all\"],\n",
    ")\n",
    "print(cache[\"resid_out_1\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interventions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
